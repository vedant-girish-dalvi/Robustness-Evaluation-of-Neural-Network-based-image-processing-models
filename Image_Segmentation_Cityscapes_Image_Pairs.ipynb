{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCYV9yM1jaUZPRWQX54wTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedantdalvi7/Robustness-Evaluation-of-neural-network-based-image-processing-models/blob/main/Image_Segmentation_Cityscapes_Image_Pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEvv-ezWtQJ6",
        "outputId": "a663e43b-c41f-4d61-a465-9488403d1177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pD0M5rzutBs2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.style.use(\"seaborn-darkgrid\")\n",
        "\n",
        "sns.set_context(\"paper\", font_scale=1.4)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "id_map = {\n",
        "    0: (0, 0, 0), # unlabelled\n",
        "    1: (111, 74,  0), #static\n",
        "    2: ( 81,  0, 81), #ground\n",
        "    3: (128, 64,127), #road\n",
        "    4: (244, 35,232), #sidewalk\n",
        "    5: (250,170,160), #parking\n",
        "    6: (230,150,140), #rail track\n",
        "    7: (70, 70, 70), #building\n",
        "    8: (102,102,156), #wall\n",
        "    9: (190,153,153), #fence\n",
        "    10: (180,165,180), #guard rail\n",
        "    11: (150,100,100), #bridge\n",
        "    12: (150,120, 90), #tunnel\n",
        "    13: (153,153,153), #pole\n",
        "    14: (153,153,153), #polegroup\n",
        "    15: (250,170, 30), #traffic light\n",
        "    16: (220,220,  0), #traffic sign\n",
        "    17: (107,142, 35), #vegetation\n",
        "    18: (152,251,152), #terrain\n",
        "    19: ( 70,130,180), #sky\n",
        "    20: (220, 20, 60), #person\n",
        "    21: (255,  0,  0), #rider\n",
        "    22: (  0,  0,142), #car\n",
        "    23: (  0,  0, 70), #truck\n",
        "    24: (  0, 60,100), #bus\n",
        "    25: (  0,  0, 90), #caravan\n",
        "    26: (  0,  0,110), #trailer\n",
        "    27: (  0, 80,100), #train\n",
        "    28: (  0,  0,230), #motorcycle\n",
        "    29: (119, 11, 32), #bicycle\n",
        "    30: (  0,  0,142) #license plate \n",
        "}\n",
        "\n",
        "category_map = {\n",
        "    0: 0,\n",
        "    1: 0,\n",
        "    2: 0,\n",
        "    3: 1,\n",
        "    4: 1,\n",
        "    5: 1,\n",
        "    6: 1,\n",
        "    7: 2,\n",
        "    8: 2,\n",
        "    9: 2,\n",
        "    10: 2,\n",
        "    11: 2,\n",
        "    12: 2,\n",
        "    13: 3,\n",
        "    14: 3,\n",
        "    15: 3,\n",
        "    16: 3,\n",
        "    17: 4,\n",
        "    18: 4,\n",
        "    19: 5,\n",
        "    20: 6,\n",
        "    21: 6,\n",
        "    22: 7,\n",
        "    23: 7,\n",
        "    24: 7,\n",
        "    25: 7,\n",
        "    26: 7,\n",
        "    27: 7,\n",
        "    28: 7,\n",
        "    29: 7,\n",
        "    30: 7\n",
        "}"
      ],
      "metadata": {
        "id": "Hxa7el8GtTcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(id_map.keys())"
      ],
      "metadata": {
        "id": "82bJLarjtTfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(path):\n",
        "    img = Image.open(path)\n",
        "    img1 = img.crop((0, 0, 256, 256)).resize((128, 128))\n",
        "    img2 = img.crop((256, 0, 512, 256)).resize((128, 128))\n",
        "    img1 = np.array(img1) / 255.\n",
        "    img2 = np.array(img2)\n",
        "    mask = np.zeros(shape=(img2.shape[0], img2.shape[1]), dtype = np.uint32)\n",
        "    for row in range(img2.shape[0]):\n",
        "        for col in range(img2.shape[1]):\n",
        "            a = img2[row, col, :]\n",
        "            final_key = None\n",
        "            final_d = None\n",
        "            for key, value in id_map.items():\n",
        "                d = np.sum(np.sqrt(pow(a - value, 2)))\n",
        "                if final_key == None:\n",
        "                    final_d = d\n",
        "                    final_key = key\n",
        "                elif d < final_d:\n",
        "                    final_d = d\n",
        "                    final_key = key\n",
        "            mask[row, col] = final_key\n",
        "    mask = np.reshape(mask, (mask.shape[0], mask.shape[1], 1))\n",
        "    del img2\n",
        "    return img1, mask"
      ],
      "metadata": {
        "id": "Hv5Y9TdztThu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_tensor_dataset(train_path, val_path):\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "    X_val = []\n",
        "    Y_val = []\n",
        "    for file in tqdm(os.listdir(train_path)):\n",
        "        img, mask = preprocess(f\"{train_path}/{file}\")\n",
        "        X_train.append(img)\n",
        "        Y_train.append(mask)\n",
        "    \n",
        "    for file in tqdm(os.listdir(val_path)):\n",
        "        img, mask = preprocess(f\"{val_path}/{file}\")\n",
        "        X_val.append(img)\n",
        "        Y_val.append(mask)\n",
        "\n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "metadata": {
        "id": "onNTw-S9tTly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_valid, Y_valid = prepare_tensor_dataset(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/train\", \"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/val\")"
      ],
      "metadata": {
        "id": "Y5xwS7shtTqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "X_valid = np.array(X_valid)\n",
        "Y_valid = np.array(Y_valid)"
      ],
      "metadata": {
        "id": "du82Y9O--_tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.save(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/X_train1.npy\")\n",
        "Y_train = np.save(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/Y_train1.npy\")\n",
        "X_valid = np.save(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/X_valid1.npy\")\n",
        "Y_valid = np.save(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/Y_valid1.npy\")"
      ],
      "metadata": {
        "id": "wN7jWR_A-s5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load variables.\n",
        "'''X_train = np.load(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/X_train.npy\")\n",
        "Y_train = np.load(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/Y_train.npy\")\n",
        "X_valid = np.load(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/X_valid.npy\")\n",
        "Y_valid = np.load(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/Y_valid.npy\")\n",
        "'''"
      ],
      "metadata": {
        "id": "pfwi_RWttTuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print info.\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "print(\"X_valid shape:\", X_valid.shape)\n",
        "print(\"Y_valid shape:\", Y_valid.shape)"
      ],
      "metadata": {
        "id": "W8y2bDWMtTxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unet_model():\n",
        "    \n",
        "    inputs = tf.keras.layers.Input(shape = [128, 128, 3])\n",
        "    \n",
        "    #First Downsample\n",
        "    f1 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(inputs)\n",
        "    b1 = tf.keras.layers.BatchNormalization()(f1)\n",
        "    f2 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b1)    # Used later for residual connection\n",
        "    \n",
        "    m3 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f2)\n",
        "    d4 = tf.keras.layers.Dropout(0.2)(m3)\n",
        "    \n",
        "    # Second Downsample\n",
        "    f5 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d4)\n",
        "    b5 = tf.keras.layers.BatchNormalization()(f5)\n",
        "    f6 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b5)    # Used later for residual connection\n",
        "    \n",
        "    m7 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f6)\n",
        "    d8 = tf.keras.layers.Dropout(0.2)(m7)\n",
        "    \n",
        "    # Third Downsample\n",
        "    f9 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d8)\n",
        "    b9 = tf.keras.layers.BatchNormalization()(f9)\n",
        "    f10 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b9)    # Used later for residual connection\n",
        "    \n",
        "    m11 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f10)\n",
        "    d12 = tf.keras.layers.Dropout(0.2)(m11)\n",
        "    \n",
        "    #Forth Downsample\n",
        "    f13 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d12)\n",
        "    b13 = tf.keras.layers.BatchNormalization()(f13)\n",
        "    f14 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b13)    # Used later for residual connection\n",
        "    \n",
        "    m15 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = 2)(f14)\n",
        "    d16 = tf.keras.layers.Dropout(0.2)(m15)\n",
        "    \n",
        "    #Fifth Downsample\n",
        "    f17 = tf.keras.layers.Conv2D(1024, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(d16)\n",
        "    b17 = tf.keras.layers.BatchNormalization()(f17)\n",
        "    f18 = tf.keras.layers.Conv2D(1024, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b17)\n",
        "\n",
        "    \n",
        "    # First Upsample\n",
        "    m19 = tf.keras.layers.UpSampling2D(size = (2, 2))(f18)\n",
        "    d19 = tf.keras.layers.Dropout(0.2)(m19)\n",
        "    c20 = tf.keras.layers.Concatenate()([d19, f14])\n",
        "    f21 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1 ,activation = \"relu\")(c20)\n",
        "    b21 = tf.keras.layers.BatchNormalization()(f21)\n",
        "    f22 = tf.keras.layers.Conv2D(512, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b21)\n",
        "    \n",
        "    # Second Upsample\n",
        "    m23 = tf.keras.layers.UpSampling2D(size = (2, 2))(f22)\n",
        "    d23 = tf.keras.layers.Dropout(0.2)(m23)\n",
        "    c24 = tf.keras.layers.Concatenate()([d23, f10])\n",
        "    f25 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c24)\n",
        "    b25 = tf.keras.layers.BatchNormalization()(f25)\n",
        "    f26 = tf.keras.layers.Conv2D(256, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b25)\n",
        "    \n",
        "    # Third Upsample\n",
        "    m27 = tf.keras.layers.UpSampling2D(size = (2, 2))(f26)\n",
        "    d27 = tf.keras.layers.Dropout(0.2)(m27)\n",
        "    c28 = tf.keras.layers.Concatenate()([d27, f6])\n",
        "    f29 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c28)\n",
        "    b29 = tf.keras.layers.BatchNormalization()(f29)\n",
        "    f30 = tf.keras.layers.Conv2D(128, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b29)\n",
        "    \n",
        "    #Forth Upsample\n",
        "    m31 = tf.keras.layers.UpSampling2D(size = (2, 2))(f30)\n",
        "    d31 = tf.keras.layers.Dropout(0.2)(m31)\n",
        "    c32 = tf.keras.layers.Concatenate()([d31, f2])\n",
        "    f33 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(c32)\n",
        "    b33 = tf.keras.layers.BatchNormalization()(f33)\n",
        "    f34 = tf.keras.layers.Conv2D(64, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"relu\")(b33)\n",
        "    \n",
        "    # Output Layer\n",
        "    outputs = tf.keras.layers.Conv2D(num_classes, kernel_size = (3, 3), padding = \"same\", strides = 1, activation = \"softmax\")(f34)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n",
        "    return model"
      ],
      "metadata": {
        "id": "FV69OjVAtT6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_unet_model()"
      ],
      "metadata": {
        "id": "dDuHJtLrtT8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes = True)"
      ],
      "metadata": {
        "id": "rPhpF6e2tT-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpdatedMeanIoU(tf.keras.metrics.MeanIoU):\n",
        "  def __init__(self,\n",
        "               y_true=None,\n",
        "               y_pred=None,\n",
        "               num_classes=None,\n",
        "               name=None,\n",
        "               dtype=None):\n",
        "    super(UpdatedMeanIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype)\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "    return super().update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "class VizCallback(tf.keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, file_path, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.file_path = file_path\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        img, mask = preprocess(self.file_path)\n",
        "        img = np.array(img)\n",
        "        img = np.reshape(img, (1, 128, 128, 3))\n",
        "        pred = model.predict(img)\n",
        "        y_pred = tf.math.argmax(pred, axis=-1)\n",
        "        y_pred = np.array(y_pred)\n",
        "        y_pred = np.reshape(y_pred, (128, 128))\n",
        "        fig, axes = plt.subplots(nrows = 1, ncols = 2)\n",
        "        axes[0].imshow(mask)\n",
        "        axes[0].set_title(\"Original Mask\")\n",
        "        axes[1].imshow(y_pred)\n",
        "        axes[1].set_title(\"Predicted Mask\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "def plot_history(history):\n",
        "  fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize=(20, 7))\n",
        "  # Training\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"loss\"], ax = axes[0], label=\"Training Loss\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"accuracy\"], ax = axes[1], label=\"Training Accuracy\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"mean_iou\"], ax = axes[2], label=\"Training Mean IOU\")\n",
        "\n",
        "  # Validation\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_loss\"], ax = axes[0], label=\"Validation Loss\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_accuracy\"], ax = axes[1], label=\"Validation Accuracy\")\n",
        "  sns.lineplot(range(1, len(history.history[\"loss\"]) + 1), history.history[\"val_mean_iou\"], ax = axes[2], label=\"Validation Mean IOU\")\n",
        "  \n",
        "  axes[0].set_title(\"Loss Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[0].set_xlabel(\"Epoch\")\n",
        "  axes[0].set_ylabel(\"Loss\")\n",
        "\n",
        "  axes[1].set_title(\"Accuracy Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[1].set_xlabel(\"Epoch\")\n",
        "  axes[1].set_ylabel(\"Accuracy\")\n",
        "\n",
        "  axes[2].set_title(\"Mean IOU Comparison\", fontdict = {'fontsize': 15})\n",
        "  axes[2].set_xlabel(\"Epoch\")\n",
        "  axes[2].set_ylabel(\"Mean IOU\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mPjLcZTmtUA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\", UpdatedMeanIoU(num_classes=num_classes, name = \"mean_iou\")])"
      ],
      "metadata": {
        "id": "EAT-EG8_tUGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience = 10, restore_best_weights = True)\n",
        "viz_callback = VizCallback(\"/content/gdrive/MyDrive/Research Project/datasets/Cityscapes_Image_Pairs/val/106.jpg\")"
      ],
      "metadata": {
        "id": "Euqj-ZmFtUIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=X_train, y=Y_train, epochs = 100, batch_size = BATCH_SIZE, validation_data = (X_valid, Y_valid), callbacks=[early_stopping, viz_callback])"
      ],
      "metadata": {
        "id": "Cr2LFdJgtULY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AciTKCN14sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bbbvgh"
      ],
      "metadata": {
        "id": "Y1bMLFA314vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hvh"
      ],
      "metadata": {
        "id": "aMAvrIfS14x0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}